fkf.R <- function(a0, P0, dt, ct, Tt, Zt, HHt, GGt, yt, smooth=FALSE) {
    T <- ncol(yt)
    N <- nrow(dt) # number of states
    d <- nrow(ct) # number of measurements

    ## state/transition equation: a_t = d_t + T_t * a_t-1 + innov, cov = HHt
    ## measurement equation:      y_t = c_t + Z_t * a_t   + innov, cov = GGt
    ## note: parameters (ct, dt, Zt, Tt, HHt, GGt) assumed to be CONSTANT -- using first element
    att <- matrix(NA, N, T)
    at <- matrix(NA, N, T+1)
    Ptt <- array(NA, c(N, N, T))
    Pt <- array(NA, c(N, N, T+1))
    vt <- matrix(NA, d, T)
    Ft <- array(NA, c(d, d, T))
    Kt <- array(NA, c(N, d, T))
    logLik = - d*T*log(sqrt(2*pi))
    at[,1] = a0
    Pt[,,1] = P0

    Z <- matrix(Zt[,,1], dim(Zt)[1], dim(Zt)[2])

    for (i in 1:T) {
        vt[, i] = yt[, i] - ct[, 1] - Z %*% at[, i]
        Ft[,, i] = Z %*% Pt[,, i] %*% t(Z) + GGt[,, 1]
        if (d==1) {
            logLik <- logLik - 0.5 * (log(Ft[,,i]) + vt[,i]^2 / Ft[,,i])
            Kt[,, i] = Pt[,, i] %*% t(Z) / Ft[,,i]
            att[, i] = at[, i] + Kt[,, i] * vt[, i]
        } else {
            ## Ft.inv <- tryCatch(solve(Ft[,, i]),
            ##                    error = {
            ##                        print("couldn't invert matrix")
            ##                        browser()
            ##                    })
            ## if (det(Ft[,,i])<1e-15)
            ##     print("pretty close to singular!")
            Ft.inv <- solve(Ft[,, i])
            if (det(Ft[,,i])<0) {
                cat("determinant of prediction error variance is negative\n")
                browser()
            }
            logLik <- logLik - 0.5 * (log(det(Ft[,,i])) + t(vt[,i]) %*% Ft.inv %*% vt[,i])
            Kt[,, i] = Pt[,, i] %*% t(Z) %*% Ft.inv
            att[, i] = at[, i] + Kt[,, i] %*% vt[, i]
        }
        Ptt[,, i] = Pt[,, i] - Pt[,, i] %*% t(Z) %*% t(Kt[,, i])
        at[, i + 1] = dt[, 1] + Tt[,, 1] %*% att[, i]
        Pt[,, i + 1] = Tt[,, 1] %*% Ptt[,, i] %*% t(Tt[,, 1]) + HHt[,, 1]
    }
    rval <- list(att=att, at=at, Ptt=Ptt, Pt=Pt, vt=vt, Ft=Ft, Kt=Kt, logLik = logLik)
    if (smooth) {
        ## based on Shumway and Stoffer
        if (any(ct!=0)|any(dt!=0)) stop("I have not verified that these derivations are correct for nonzero intercepts")
        atT <- matrix(NA, N, T)
        PtT <- array(NA, c(N, N, T))
        Jt <- array(NA, c(N, N, T))
        atT[, T] <- att[, T]
        PtT[,, T] <- Ptt[,, T]
        for (t in (T-1):1) {
            Jt[,, t] <- Ptt[,, t] %*% t(Tt[,, 1]) %*% solve(Pt[,,t+1])
            atT[, t] <- att[, t] + Jt[,, t] %*% (atT[, t+1] - at[, t+1])
            PtT[,, t] <- Ptt[,, t] + Jt[,, t] %*% (PtT[,, t+1] - Pt[,, t+1]) %*% t(Jt[,, t])
        }
        CtT <- array(NA, c(N, N, T)) # CtT[,,t] = Cov(x(t), x(t-1)|data)
        CtT[,, T] <- (diag(N) - Kt[,, T] %*% Z) %*% Tt[,, 1] %*% Ptt[,, T-1]
        for (t in (T-1):2)
            CtT[,, t] <- Ptt[,,t] %*% t(Jt[,,t-1]) + Jt[,,t] %*% (CtT[,, t+1] - Tt[,, 1]%*%Ptt[,, t]) %*% t(Jt[,, t-1])
        rval$atT <- atT
        rval$PtT <- PtT
        rval$CtT <- CtT
    }
    rval
}

updateEM <- function(y, pars) {
    p <- length(pars$phi)
    T <- length(y)
    stopifnot(length(pars$theta)==0) # only implemented for RW+AR(p)+noise
    ## E-step: obtain smoothed states and covariance matrices
    kf <- kalman.uc(pars, y, smooth=TRUE)
    ## M-step: obtain parameters that maximize expected likelihood
    ## 1) estimate of phi
    A <- matrix(0, p, p)
    B <- matrix(0, p, 1)
    for (t in 2:T) {
        A <- A + kf$atT[-1,t-1] %*% t(kf$atT[-1,t-1]) + kf$PtT[-1,-1,t-1]
        B <- B + kf$atT[-1,t-1] * kf$atT[2,t] + kf$CtT[2,-1,t]
    }
    pars$phi <- solve(A) %*% B
    ## 2) variances
    etaT <- kf$atT[1,2:T] - kf$atT[1,1:(T-1)]
    pars$sigeta2 <- mean(etaT^2 + kf$PtT[1,1,2:T] - 2*kf$CtT[1,1,2:T] + kf$PtT[1,1,1:(T-1)])
    vT <- kf$atT[2,2:T] - t(pars$phi) %*% kf$atT[-1,1:(T-1)]
    pars$sigv2 <- mean(vT^2 + kf$PtT[2,2,2:T] - 2*t(pars$phi)%*%kf$CtT[2,-1,2:T] + sapply(1:(T-1), function(tm1) t(pars$phi) %*% kf$PtT[-1,-1,tm1] %*% pars$phi))
    alpha <- matrix(c(1, 1, rep(0, p-1)), 1, p+1)
    eT <- y - alpha %*% kf$atT
    pars$sig2 <- mean(eT^2 + sapply(1:T, function(t) alpha %*% kf$PtT[,,t] %*% t(alpha)))
    pars
}

stateSpaceMats <- function(pars, pi0=4, v0=100) {
    uCovVar <- function(phi, omega) {
        ## unconditional covariance matrix of VAR(1)
        ## - can also be used to find unconditional variance of AR(p) process by using companion form
        N <- nrow(omega)
        matrix(solve(diag(N^2) - kronecker(phi, phi)) %*% as.numeric(omega), N, N)
    }
    p <- length(pars$phi)
    N <- p + 1
    if (length(pars$theta)>0)
        stop("this is for AR(p) only, no MA terms allowed")
    ## measurement equation
    ct <- matrix(0, 1, 1)
    Zt <- array(c(1, 1, rep(0, p-1)), c(1, N, 1))
    GGt <- array(pars$sig2, c(1, 1, 1))
    ## transition equation
    dt <- matrix(0, N, 1)
    if (p==1) {
        F <- diag(c(1, pars$phi))
    } else {
        F <- rbind(c(1, rep(0, p)),
                   c(0, pars$phi),
                   cbind(0, diag(p-1), 0))
    }
    Tt <- array(F, c(N, N, 1))
    Omega <- matrix(diag(c(pars$sigeta2, pars$sigv2, rep(0, p-1))), N, N)
    HHt <- array(Omega, c(N, N, 1))
    ## initial conditions
    a0 <- c(pi0, rep(0, p))
    if (p==1) {
        P0 <- rbind(c(v0, rep(0, p)),
                    cbind(0, matrix(1/(1 - F[2,2]) %*% as.numeric(Omega[-1,-1]), p, p)))
    } else {
        P0 <- rbind(c(v0, rep(0, p)),
                    cbind(0, uCovVar(F[-1,-1], Omega[-1,-1])))
    }
    list(a0=a0, P0=P0, dt=dt, ct=ct, Tt=Tt, Zt=Zt, HHt=HHt, GGt=GGt)
}

kalman.uc <- function(pars, y, smooth=FALSE, pi0=4, v0=100) {
    ## Kalman filter for UC model: RW + AR(p) + noise
    rval <- stateSpaceMats(pars, pi0, v0)
    ## call Kalman filter/smoother
    if (smooth) {
        do.call(fkf.R, c(rval, list(yt=matrix(y, 1, length(y)), smooth=TRUE)))
    } else {
        require(FKF)
        do.call(fkf, c(rval, list(yt = matrix(y, 1, length(y)))))
    }
}

simData.uc <- function(pars, T) {
    N <- length(pars$a0)
    X <- matrix(NA, N, T)
    P0 <- pars$P0
    ## initial values
    X[,1] <- pars$a0 + t(chol(P0)) %*% rnorm(N)
    ## simulation
    for (t in 2:T)
        X[,t] <- pars$dt + pars$Tt[,,] %*% X[,t-1] + c(rnorm(2, sd=sqrt(c(pars$sigeta2, pars$sigv2))), rep(0, N-2))
    data.frame(trend = X[1,], cycle = X[2,],
               pi = X[1,] + X[2,] + rnorm(T, sd=sqrt(pars$sig2)))
}

getSigEta2 <- function(tau, phi, sigv2) {
    ## for UC model that is paramterized in terms of tau, obtain sig_nu^2
    MAsum <- 1
    ARsum <- 1-sum(phi)
    LRV <- MAsum^2/ARsum^2*sigv2
    ## tau = sqrt(pars$sigeta2)/sqrt(LRV)
    sigeta2 <- tau^2 * LRV
}

checkKKT <- function(theta, obj) {
    ## check result of numerical optimization
    require(numDeriv)
    y <- obj(theta)
    kkttol <- 10*.Machine$double.eps^(1/4)
    kkt2tol <- 100* (.Machine$double.eps^(1/4))
    ngatend <- grad(obj, theta)
    cat("Gradient:")
    print(ngatend)
    kkt1 <- max(abs(ngatend)) <= kkttol*(1.0+abs(y))
    cat("kkt1 = ", kkt1, "\n")
    nhatend <- hessian(obj, theta)
    hev <- eigen(nhatend)$values
    cat("Eigenvalues:", hev, "\n")
    negeig <- (hev <= -kkttol*(1+abs(y)))
    cat("negeig = ", negeig, "\n")
    evratio <- tail(hev, 1)/hev[1]
    cat("evratio =", evratio, "\n")
    cat("evratio requirement >", kkt2tol,"\n")
    kkt2 <- (evratio > kkt2tol) && (!negeig)
    cat("kkt2 =", kkt2, "\n")
}

DurbinLevinson <- function(a) {
    ## used in gamma2pars()
    p <- length(a)
    alpha <- matrix(NA, p, p)
    for (j in 1:p)
        alpha[1:j,j] <- c(alpha[1:(j-1),j-1] - a[j]*alpha[(j-1):1,j-1], a[j])
    alpha[,p]
}
require(compiler)
DL.fast <- cmpfun(DurbinLevinson)

est.uc <- function(y, p, TAU=NA, SIG2=NA, nstarts=10, eps=.001, dgp=NULL) {
    ## Estimate Unobserved Component Model using Kalman filter and MLE
    ##  y = trend (RW) + cycle (AR) + noise
    ##  sig_eta^2 = random walk innovation variance
    ##  sig_v^2  = cycle innovation variance
    ##  sig^2    = noise variance
    ## Arguments:
    ##  y - data
    ##  p - number of AR terms for cycle
    ##  TAU - signal-to-noise ratio. tau = SD(RW innovation)/LRSD(cycle)
    ##  SIG2 - measurement error (noise) variance
    ##  TAU and SIG2  can be left free (NA) or fixed (number)
    ##  nstarts - number of starting values for initial optimization
    ##  dgp - list with DGP parameters if data was simulated
    nvars <- 1 + is.na(TAU) + is.na(SIG2) # number of free parameters other than ARMA coeffs
    gamma2pars <- function(gamma) {
        if (length(gamma)!=p+nvars)
            stop("parameter vector has the wrong length")
        pars <- list(sigv2 = exp(gamma[p+1]))
        pars$tau <- ifelse(is.na(TAU), exp(gamma[p+2]), TAU)
        pars$sig2 <- ifelse(is.na(SIG2), exp(gamma[p+nvars]), SIG2)
        ## transform unrestricted u to AR coefficients
        u <- gamma[1:p]
        a <- (1-exp(-u))/(1+exp(-u)) # PACFs constrained to (-1,1) -> ensures stationarity
        pars$phi <- DL.fast(a)
        pars$sigeta2 <- getSigEta2(pars$tau, pars$phi, pars$sigv2)
        pars
    }
    pars2gamma <- function(pars) {
        ## transform AR coefficients to unrestricted u
        a <- ARMAacf(ar=pars$phi, pacf=TRUE) ## PACFs implied by AR(p)
        u <- -log((1-a)/(1+a))
        rval <- c(u, log(pars$sigv2))
        if (is.na(TAU))
            rval <- c(rval, log(pars$tau))
        if (is.na(SIG2))
            rval <- c(rval, log(pars$sig2))
        rval
    }
    obj <- function(gamma) {
        ## objective function for maximum likelihood estimation
        penalty <- 5000
        if (any(abs(gamma)>10))
            return(penalty)
        pars <- gamma2pars(gamma)
        -kalman.uc(pars, y)$logLik
    }
    optEM <- function(pars, eps) {
        llk <- kalman.uc(pars, y)$logLik
        improve <- Inf
        while (improve > eps) {
            pars <- updateEM(y, pars)
            llk.new <- kalman.uc(pars, y)$logLik
            if (is.na(llk.new)) {
                improve <- 0
            } else {
                improve <- llk.new - llk
            }
            llk <- llk.new
        }
        list(pars=pars, logLik=llk)
    }
    ## random starting values
    cat("# Optimization from", nstarts, "different starting values\n")
    best.llk <- -Inf
    nms <- c("starting LLK", "optimal LLK", "sigv2")
    if (is.na(TAU)) {
        nms <- c(nms, "tau")
    }
    if (is.na(SIG2)) {
        nms <- c(nms, "sigma^2")
    }
    tbl <- matrix(NA, nstarts, length(nms))
    colnames(tbl) <- nms
    for (i in 1:nstarts) {
        ## random starting value
        gamma0 <- c(rnorm(p, sd=2), log(runif(nvars, 0.01, .5)))
        pars0 <- gamma2pars(gamma0)
        ## optimize using EM algorithm
        rval <- optEM(pars0, eps)
        tbl[i, ] <- c(-obj(gamma0), rval$logLik, unlist(rval$pars[c("sigv2", "tau", "sig2")]))
        cat("Optimization", i, "- starting value", -obj(gamma0), "maximal value", rval$logLik, "...\n")
        if (!is.na(rval$logLik) && rval$logLik > best.llk) {
            best.llk <- rval$logLik
            pars <- rval$pars
            gamma <- pars2gamma(pars)
            cat("best LLK improved to", best.llk, "\n")
        }
    }
    print(round(tbl[order(tbl[,2], decreasing=TRUE),], 2))
    stopifnot(all.equal(gamma, pars2gamma(gamma2pars(gamma))))
    ## optimization
    cat("# Final optimization. LLK at starting values:", -obj(gamma), "\n")
    cat("# 1. Nelder-Mead optimization...\n")
    rval <- optim(gamma, obj, control=list(maxit=10000))
    print(rval)
    gamma <- rval$par
    cat("# 2. gradient-based method...\n")
    rval <- optim(gamma, obj, method="L-BFGS-B", hessian=TRUE)
    print(rval[-6])
    H <- rval$hessian
    cat("Hessian eigenvalues", round(eigen(H)$values, 4), "\n")
    gamma <- rval$par
    checkKKT(gamma, obj)
    cat("likelihood at optimum:", -obj(gamma), "\n")
    pars <- gamma2pars(gamma)

    ## look at results
    cat("# Parameters in unconstrained space and standard errors:\n")
    SEs <- sqrt(diag(solve(H)))
    tbl <- cbind(gamma, SEs, grad(obj, gamma), diag(H))
    print(round(tbl, d=4))
    cat("abs(AR roots):", abs(polyroot(c(1, -pars$phi))), "\n")

    getParVec <- function(pars) {
        ## (named) vector with parameters
        x <- pars$phi
        nms <- paste("AR", 1:p)
        x <- c(x, pars$sigv2)
        nms <- c(nms, "sigma_v^2")
        if (is.na(TAU)) {
            x <- c(x, pars$tau)
            nms <- c(nms, "tau")
        }
        if (is.na(SIG2)) {
            x <- c(x, pars$sig2)
            nms <- c(nms, "sig2")
        }
        setNames(x, nms)
    }
    getStatVec <- function(pars) {
        ## (named) vector with LLK and summary stats
        llk <- kalman.uc(pars, y)$logLik
        ARsum <- 1-sum(pars$phi)
        LRV <- 1/ARsum^2*pars$sigv2
        signal.to.noise <- sqrt(pars$sigeta2)/sqrt(LRV)
        setNames(c(pars$sigeta2, llk, ARsum, signal.to.noise),
                 c("sigma_eta^2", "LLK", "AR-sum", "signal-to-noise"))
    }
    x2pars <- function(x) {
        pars <- list(phi = x[1:p],
                     sigv2 = x[p+1])
        pars$tau <- ifelse(is.na(TAU), x[p+2], TAU)
        pars$sig2 <- ifelse(is.na(SIG2), x[p+nvars], SIG2)
        pars$sigeta2 <- getSigEta2(pars$tau, pars$phi, pars$sigv2)
        pars
    }
    obj2 <- function(x) {
        pars <- x2pars(x)
        -kalman.uc(pars, y)$logLik
    }
    x <- getParVec(pars)
    stopifnot(all.equal(obj2(x), obj(gamma)))
    ## (H2 <- hessian(obj2, x, method.args=list(eps=1e-11)))
    ## if (~any(is.na(H2)))
    cat("Hessian eigenvalues", round(eigen(H)$values, 4), "\n")
    SEs <- sqrt(diag(solve(H)))

    cat("Table with parameters (standard errors) and summary statistics:\n")
    stats <- getStatVec(pars)
    tbl <- cbind(c(x, stats), c(SEs, rep(NA, length(stats))))
    rownames(tbl) <- c(names(x), names(stats))
    colnames(tbl) <- c("Estimates", "SEs")

    if (!is.null(dgp)) {
        ## data was simulated
        ## DGP parameters and LLK at those
        tbl <- cbind(tbl, c(getParVec(dgp), getStatVec(dgp)))
        colnames(tbl)[3] <- "DGP"
        cat("# data was simulated\n")
        cat("optimization using DGP parameters as starting values...\n")
        rval <- optim(pars2gamma(dgp), obj, method="L-BFGS-B", hessian=TRUE)
        cat("Hessian eigenvalues", round(eigen(rval$hessian)$values, 4), "\n")
        gamma <- rval$par
        checkKKT(gamma, obj)
        print(rval[-6])
        tbl <- cbind(tbl, c(getParVec(pars), getStatVec(pars)))
        ## comforting if optimization reaches the same optimum as this one
    }

    print(round(tbl, d=4))

    pars
}
