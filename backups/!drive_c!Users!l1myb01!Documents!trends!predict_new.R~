## some alternative specifications with i*
## findings:
## - using PCs of detrended yields helps a lot
## - though doesn't work quite as well as leaving it unrestricted
## - maybe more ROBUST to use detrended yields instead of unrestricted

rm(list=ls())
require(sandwich) # NeweyWest()
require(xtable) # xtable()
source("R/trends_fns.r")

subsample <- FALSE

df <- loadData()
if (subsample)
    df <- df[df$yyyymm >= 198501, ]
cat("Date range:", range(df$yyyymm), "\n")

## PCs of yields
Y <- data.matrix(df[,attr(df, "yield.cols")])
W <- eigen(cov(Y))$vectors[,1:3]
mats <- c(0.25, 0.5, 1:15)
df[paste0("PC", 1:3)] <- Y %*% W
## detrended yields
Yd <- Y - df$pistar.ptr - df$rstar.mean # our recommendation
Ycpo <- Y - df$pistar.ptr # CPO - simple difference
Ycpo <- apply(Y, 2, function(y) resid(lm(y ~ df$pistar.ptr))) # CPO - residuals

## PCs of detrended yields
## Wd <- eigen(cov(Yd))$vectors[,1:3]
df[paste0("PCd", 1:3)] <- Yd %*% W
## CPO cycles
df$c1 <- Yd[,3]
df$cbar <- rowMeans(Yd[,3:17])
df$cpo1 <- Ycpo[,3]
df$cpobar <- rowMeans(Ycpo[,3:17])
df$y1 <- Y[,3]
df$ybar <- rowMeans(Y[,3:17])

T <- nrow(Y)
tbl <- data.frame(matrix(NA, 11, 9))
tbl[,1] <- sprintf("%-15s", c("PC1", "",
                              "PC2", "",
                              "PC3", "",
                              "$\\pi_t^\\ast$", "",
                              "$r_t^\\ast$", "",
                              "$R^2$"))

## holding period
h <- 4
if (h==1) {
    vcovfn <- function(mod) vcovHC(mod, "HC")
} else if (h==4) {
    vcovfn <- function(mod) NeweyWest(mod, lag=6, prewhite=FALSE)
}

## calculate excess returns
for (n in 2:15) {
    nm <- paste0("xr", n)
    df[nm] <- c(-(n-h/4)*Y[(1+h):T, mats==ifelse(h==1, n, n-1)] + n*Y[1:(T-h), mats==n] - h/4*Y[1:(T-h), mats==h/4], rep(NA, h))
}
df$xr.avg <- rowMeans(as.matrix(df[paste0("xr", 2:15)]))

col <- 2
for (i in 1:9) {
    switch(i,
    { ## 1
        fmla <- xr.avg ~ PC1 + PC2 + PC3 + pistar.ptr + rstar.mean;
        regrows <- c(1,3,5,7,9)
    },
    { ## 2
        fmla <- xr.avg ~ PC1 + PC2 + pistar.ptr + rstar.mean
        regrows <- c(1,3,7,9)
    },
    { ## 3
        fmla <- xr.avg ~ PCd1 + PCd2 + PCd3
        regrows <- c(1,3,5)
    },
    { ## 4
        fmla <- xr.avg ~ PCd1 + PCd2
        regrows <- c(1,3)
    },
    { ## 5
        fmla <- xr.avg ~ PC1 + PC2 + PC3
        regrows <- c(1,3,5)
    },
    { ## 6
        fmla <- xr.avg ~ PC1 + PC2
        regrows <- c(1,3)
    },
    { ## 7
        fmla <- xr.avg ~ ybar + y1
        regrows <- c(1,3)
    },
    { ## 8
        fmla <- xr.avg ~ cpobar + cpo1
        regrows <- c(1,3)
        df$cf_cpo <- c(fitted(lm(fmla, df)), rep(NA, h))
    },
    { ## 9
        fmla <- xr.avg ~ cbar + c1
        regrows <- c(1,3)
        df$cf <- c(fitted(lm(fmla, df)), rep(NA, h))
    })
    mod <- lm(fmla, df)
    tbl[regrows, col] <- mod$coef[-1]
    V <- vcovfn(mod)
    tbl[regrows+1, col] <- sqrt(diag(V))[-1]
    tbl[nrow(tbl), col] <- summary(mod)$r.squared
    col <- col+1
}
tbl[,-1] <- formatTbl(tbl[,-1], se.rows=c(2,4,6,8,10))

## ## bootstrap p-values
## tbl <- rbind(tbl[1:8,], "", tbl[9:10,], "", tbl[11,])
## for (h in c(1, 4)) {
##     if (h==1) {
##         vcovfn <- function(mod) vcovHC(mod, "HC")
##         fmla1 <- xr.q ~ PC1 + PC2 + PC3
##         fmla2a <- xr.q ~ PC1 + PC2 + PC3 + pistar.ptr
##         fmla2b <- xr.q ~ PC1 + PC2 + PC3 + pistar.ptr + rstar.mean
##     } else if (h==4) {
##         vcovfn <- vcovNW
##         fmla1 <- xr.a ~ PC1 + PC2 + PC3
##         fmla2a <- xr.a ~ PC1 + PC2 + PC3 + pistar.ptr
##         fmla2b <- xr.a ~ PC1 + PC2 + PC3 + pistar.ptr + rstar.mean
##     }
##     ## pi-star only
##     rval <- bootstrapTest(fmla1, fmla2a, df, dgp, h=h, vcovfn=vcovfn, M=5000)
##     tbl[9, 2+h] <- sprintf("[%4.2f]", rval$tblCoef[5, 4])
##     ##print(round(rval$tblCoef, 2))
##     ##print(round(rval$tblR2, 3))
##     ## pi-star and r-star
##     rval <- bootstrapTest(fmla1, fmla2b, df, dgp, h=h, vcovfn=vcovfn, M=5000)
##     tbl[c(9, 12), 3+h] <- sprintf("[%4.2f]", as.numeric(rval$tblCoef[5, 4:5]))
##     ##print(round(rval$tblCoef, 2))
##     ##print(round(rval$tblR2, 3))
## }

print(tbl)

stats <- function(fmla) {
    mod <- lm(fmla, df)
    b <- mod$coef[-1]
    V <- vcovfn(mod)
    SEs <- sqrt(diag(V))[-1]
    tmp <- cbind(b, b/SEs)
    round(c(as.numeric(t(tmp)), summary(mod)$r.squared), 3)
}

tbl <- data.frame(matrix(NA, 3+3+5, 14))
tbl[,1] <- c("cf_cpo", "t-stat", "R^2", "cf", "t-stat", "R^2", "cf_cpo", "t-stat", "cf", "t-stat", "R^2")
for (n in 2:15) {
    depvar <- paste0("xr", n)
    tbl[1:3, n] <- stats(get(depvar) ~ cf_cpo)
    tbl[4:6, n] <- stats(get(depvar) ~ cf)
    tbl[7:11, n] <- stats(get(depvar) ~ cf + cf_cpo)
}
print(tbl)
## doesn't make sense to throw in two such highly correlated factors

bootstrapTest <- function(fmla1, fmla2, data, dgp, h, M=1000, vcovfn, adjR2=FALSE) {
    require(sandwich)
    require(lmtest)
    regnames <- attr(terms(fmla2), "term.labels")
    K <- length(regnames)
    K1 <- length(attr(terms(fmla1), "term.labels"))
    K2 <- K - K1
    depvar <- deparse(fmla1[[2]])
    R2fn <- if (adjR2) {
        function(mod) summary(mod)$adj.r.squared
    } else {
        function(mod) summary(mod)$r.squared
    }

    ## tables with results
    tblCoef <- matrix(NA, 7, K + 1)  ## 3 rows for data, 2 rows for bootstrap
    colnames(tblCoef) <- c(regnames, "Wald")
    rownames(tblCoef) <- c("Coefficient", "HAC statistic", "HAC $p$-value",
                           "Bootstrap 5\\% c.v.", "Bootstrap $p$-value",
                           "IM $q=8$", "IM $q=16$")
    tblR2 <- matrix(NA, 3, 6)
    rownames(tblR2) <- c("Data", "Bootstrap mean", "95% bootstrap interval")
    colnames(tblR2) <- c("R^2_1", "", "R^2_2", "", "R^2_2 - R^2_1", "")

    ## data
    lm1 <- lm(fmla1, data=data)
    lm2 <- lm(fmla2, data=data)
    T <- length(lm2$residuals) + ifelse(any(grep("PC", depvar)), 1, 0)
    tblCoef[1, 1:K] <- lm2$coef[-1]
    ## HAC inference
    SEs <- sqrt(diag(vcovfn(lm2)))
    tstats <- (lm2$coef/SEs)[-1]
    tblCoef[2, 1:K] <- tstats
    tblCoef[3, 1:K] <- pnorm(abs(tstats), lower.tail=FALSE)*2
    ## tblCoef[3, 1:K] <- pt(abs(tstats), lm2$df, lower.tail=FALSE)*2
    rval <- waldtest(lm1, lm2, vcov=vcovfn, test="Chisq")
    stopifnot(K2 == rval$Df[2])  # check degrees of freedom
    tblCoef[2, K+1] <- rval$Chi[2]
    tblCoef[3, K+1] <- rval$Pr[2]
    ## IM test
    tblCoef[6:7, 1:K] <- getMuellerTable(fmla2, data)[-1,]
    ## R^2
    tblR2[1, c(1,3,5)] <- c(R2fn(lm1), R2fn(lm2), R2fn(lm2) - R2fn(lm1))

    ## bootstrapping
    cat("# Simulating bootstrap samples: T =", T, ", M =", M, "...\n")
    statsHAC <- matrix(NA, M, K+1)
    pvalsHAC <- matrix(NA, M, K+1)
    R2.r <- numeric(M)
    R2.ur <- numeric(M)
    for (b in 1:M) {
        simData <- simulateData(dgp, T, h)
        mod1 <- lm(fmla1, data=simData)
        mod2 <- lm(fmla2, data=simData)
        R2.r[b] <- R2fn(mod1)
        R2.ur[b] <- R2fn(mod2)
        ## HAC
        SEs <- sqrt(diag(vcovfn(mod2)))
        statsHAC[b, 1:K] <- abs(mod2$coef/SEs)[-1]
        pvalsHAC[b, 1:K] <- pnorm(statsHAC[b, 1:K], lower.tail=FALSE)*2
        ## pvalsHAC[b, 1:K] <- pt(statsHAC[b, 1:K], mod2$df, lower.tail=FALSE)*2
        rval <- waldtest(mod1, mod2, vcov=vcovfn, test="Chisq")
        statsHAC[b, K+1] <- rval$Chi[2]
        pvalsHAC[b, K+1] <- rval$Pr[2]
    }
    if (lm2$df != mod2$df)
        stop("degrees of freedom not the same in actual and simulated data")
    tblCoef[4, ] <- apply(statsHAC, 2, quantile, .95)  ## bootstrap critical values
    tblCoef[5, ] <- colMeans(statsHAC > rep(abs(tblCoef[2, ]), each=M))
    tblCoef[4:5, 1:K1] <- NA
    ## tblSize[1, ] <- colMeans(pvalsHAC < 0.05)
    ## tblSize[1:4, 1:K1] <- NA
    tblR2[2,c(1,3,5)] <- colMeans(cbind(R2.r, R2.ur, R2.ur-R2.r))      ## means
    tblR2[3, 1:2] <- quantile(R2.r, c(.025, .975))
    tblR2[3, 3:4] <- quantile(R2.ur, c(.025, .975))
    tblR2[3, 5:6] <- quantile(R2.ur-R2.r, c(.025, .975))
    list(tblCoef=tblCoef, tblR2=tblR2)
}
