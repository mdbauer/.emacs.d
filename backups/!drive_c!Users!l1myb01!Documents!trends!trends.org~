* Next actions
** TODO edits to paper
*** cite Crump et al, Del Negro et al
*** cite Ed Nelson's paper on real-rate gap
*** introduce i* in the context of Figure 1
Greg: the only thing that matters is i*. Glenn: I replied that
we’d agree with that, but also note that having r* and pi* helps
uncover i*.  We should be much clearer about this in the next
revision.

*** Let’s also change the titles of tables 4 and 5 in the paper to
Predicting excess returns with macro trends
Predicting excess returns with de-trended yields
*** discussion of interest rate cycles
the paragraph on interest rate cycles in the bottom half of page 19
should be moved to section 4, say to the bottom of page 14.

*** earlier ideas for edits
**** acknowledge that neither Cieslak-Povala nor van Dijk et al imposed unit coefficient on pi*
**** LR Fisher effect
 - cite [[file:~/Documents/Papers/J/Jensen%20(2009)%20The%20Long-Run%20Fisher%20Effect_%20Can%20It%20Be%20Tested.pdf][Jensen's paper]]
 - mention that coefficients are larger than one not because of tax
   effects but because of the role of r*
**** big picture/introduction
 - Watson says that before their UCSV paper, people had been using
   IMA(1,1) models for inflation for 40 years
   - cite additional papers and long tradition of modeling inflation as
     integrated
 - also cite papers on [[*persistence of interest rates][persistence in interest rates]]
   - early literature on I(1) tests of interest rates (see below)
   - Ball and Torous, Kim-Orphanides
   - Fama (2006) argues that there is a time-varying mean! also cite
     other papers on shifting endpoints (Orphanides-Wei etc)
 - one of our key questions is whether y(t)-pi*(t) is persistent
   because of a trend in the real rate, a trend in the term premium, or both
   - our answer is that it's mainly r*, based on evidence in sections 4-6
   - however, in section 7 the evidence suggests that the trend in the
     term premium is also important
   - need to be really clear about how our evidence fits together, and
     what our overall message is
   - also: are there other ways to answer this question?
 - be more forceful in our critique of existing literature: all affine
   term structure models are misspecified in the sense that mean
   reversion to constant mean is way too quick
   - we know it's better to have a random walk
     - Duffee has a model with a RW for the level which forecasts well
   - but even better to have shifting endpoint
     - note few papers that have that, but aren't correctly modeling r*
 - emphasize that we find an important role for the expectations
   component
   - using outside macro estimates we are actually able to explain
     interest rate swings at low frequencies
   - that's a pretty high bar
   - the explanation works through the expectations hypothesis
**** PCs of trending variables not okay
 - mention that PCA only appropriate for stationary variables
 - if there is a stochastic trend results can be
   misleading otherwise
** DONE [#A] analysis of changes
- regress changes in yields on changes in pi* and r*
  - different frequencies

test:
- coefficients equal to each other
- coefficients (individually/jointly) equal to one

** TODO [#A] estimate error correction model
Goal: show that there is equilibrium correction of yields

questions:
- intercept for cointegration residual? -- probably not needed
- number of lags? -- just use 4 for now

What does it mean that an intercept is necessary? Is this a reasonable specification?
Similar results if
(a) include intercept in each equation, or
(b) demean cointegration residual first, don't include intercepts

** TODO [#B] inference about cointegration vectors -- DOLS tests
*** DOLS - Stock and Watson (1993)
- check conditions under which standard inference is valid
- in particular, check cross-correlations of cointegration residual
  with pi* and r*. critical assumption is that these are zero at all
  leads and lags.
- check Granger causality from Delta y2_t (changes in * variables) to
  Delta y1_t (changes in interest rates)
- if assumptions are violated, can include lags and leads of changes
  in y2
- only test coefficients about cointegrating vector if there IS
  cointegration -- otherwise spurious regression, nonstd distribution
- see Hamilton chapter 19
- standard reference is Stock and Watson (1993, Ecta) "A Simple
  Estimator..."
- see also high-level intuitive explanation in Zivot's book, chapt 12,
  https://faculty.washington.edu/ezivot/econ584/notes/cointegration.pdf
*** Johansen MLE - Johansen, 1988
*** fully-modified least squares - Phillips and Hansen (1990)
*** persistence: Stock's vonfidence interval for AR coefficient
*** persistence: median unbiased estimate of AR coefficient
** TODO [#A] additional unit root tests
- include pi* and r*
- low-frequency econometrics -- LFST results
- DF-GLS and KPSS -- like in Mueller-Watson (2013)
- more state-of-the-art tests: see Rapach-Weber (2004) Are real interest rates really nonstationary
  for state-of-the-art tests
  - ERS ADF-GLS test using Ng-Perron lag length selection
  - MZ_alpha^GLS of Ng-Perron
- stationary tests
*** Mueller-Watson low-frequency econometrics
[[file:~/org/notes.org::*Mueller-Watson%20low-frequency%20econometrics][paper summaries and notes]]
next:
- first do it myself: calculate low-frequency component using projection
  - compare MW and Schorfheide parameterization--which one is right?
- then: run and understand code from Watson's website
  - start with LFE

Goals:
- test I(0) vs I(1) for
  - long-term rates
  - pi*, r*
  - pi, r
- test cointegration, i.e. test I(0) of
  - y - pi - r
  - y - pi* - r*

** TODO [#B] Johansen test for number of common trends in interest rates, inflation, and real rate
- interest rates presumably have just one common trend (i* = pi*+r*)
- but augmenting by inflation OR real rate should lead to two common
  trends

possible methodologies:
- Stock and Waton
- Johansen

** TODO [#A] revise term premium section
- relate to Cochrane's analysis, cite his comment/paper
  - we are doing something similar to what he did -- justify
    methodology
  - but we resolve the problem he points out!
- tie this in better with the rest of our paper
- include survey-based term premium and Kim-Wright/ACM
*** TODO can we use excess return regressions after all?
- [[file:~/Papers/L/Ludvigson%20and%20Ng%20(2009,%20RFS)%20Macro%20Factors%20in%20Bond%20Risk%20Premia.pdf][Ludvigson and Ng (2009)]] use a monthly VAR(12) with 10 variables:
  excess returns, CP, and five macro factors
- [[file:~/Papers/R/Rudebusch-Sack-Swanson%20(2007)%20Macroeconomic%20Implications%20of%20Changes%20in%20the%20Term%20Premium.pdf][Rudebusch, Sack, Swanson]] iterate forward expected Cochrane-Piazzesi
  factor following [[file:~/Papers/S/Sack%20(2006).pdf][Sack (2006)]]

What we could do:
- we have 15 years yield maturities
- can calculate out to 10-year term premium if we use yield factors
  that only depend on first 5 years of yields
- yield information either summarized by CP factor -- assume same
  linear combination across maturities -- or simply by three yields,
  e.g. 1y/3y/5y, or three forward rates

*** TODO can we use our model?
*** TODO review analysis in trends/archive/tpnew

** TODO [#A] OOS: include Blue Chip forecasts and AR(1)/stationary DTSM
** TODO [#A] OOS: Welch-Goyal figures with relative performance
** TODO more ideas for OOS yield forecasting
- constant mean/AR(1) forecasts
- use constant and scaling from cointegration regression -- for pi*
  this is what van Dijk et al are doing (except for they are doing
  it for the level factor instead of for individual interest rates)
- use Diebold-Li model, do what we do for the level factor
- forecasts from shifting endpoint VAR
** TODO more rigorous econometrics -- estimation uncertainty, meas. error, generated regressors
- generated regressors -- in which way is this an issue?

IDEA: coherent econometric framework to test our hypotheses
- replace average/r* data by latent r* and add measurement equations
- in this way, account for estimation uncertainty
- measurement errors serially correlated

hypotheses:
- cointegration vector (DOLS)
- unit root/persistence of detrended yields

** TODO benefit of macro vs yield-based (MA) estimates of i*
- Cieslak-Povala show DMA of past yields does not work as a predictor
- van Dijk et al show that endpoint pased on past interest rates does
  not work
- Kevin isn't convinced: "[CPO's] result that the trend in say 1 year
  treasuries doesn’t work but the trend in inflation does work seems
  very strange. Just look at Figure 1 in my paper. Inflation and short
  term Treasury yields are move together. I think it could be due to
  the way the trend in 1 year treasury yield is constructed. They use
  a simple discounted moving average. May need to use something more
  sophisticated."
- can we show why macro-based estimates work but finance-based do not?
** TODO [#C] revisit variance ratios
- if there is another metric where r* comes in strong, that would be
  helpful
- think some more about Duffee vs Campbell-Ammer
- but in general keep it on the back burner
*** TODO variance ratios for *returns*
- can we redo/reconcile Campbell/Ammer
- different holding periods -- up to h=40

*** TODO make point that pi*/r* are major source of RISK to LT bond investors
*** discussion with Thomas on this issue
intuitively, it *has* to be the case that inflation expectations are the most important driver
of long-term interest rates [at low frequencies]!
- eqbm real rate may have moved a little but no huge swings in
  productivity or marginal product of capital
- risk premia [are volatile but] move slowly and are not trending

Thomas:
- idea: estimate r* from fundamentals, add it to pi*, get a
  "theoretical" interest rate, compare to actual interest rate
- pointed out [[file:~/Papers/S/Shiller%20(1979)%20The%20Volatility%20of%20Long-Term%20Interest%20Rates%20and%20Expectations%20Models%20of%20the%20Term%20Structure.pdf][Shiller's classic paper on excess volatility and inflation]]

*** econometrics of confidence interval for ratio of variances
- central limit theorems for variances and correlation coefficients
http://www.edwardomey.com/nonsave/CLTforsandr.pdf

Approximations for Mean and Variance of a Ratio
[[file:../trends/papers and materials/ratio.pdf]]
-> closely related to delta method

related:
- influence curves/delta method
- influence function/asymptotic linearity
  - http://www.biostat.jhsph.edu/bstcourse/bio771/sec10.pdf
  - https://www.stat.berkeley.edu/~laan/Class/Class_subpages/asymptbook.pdf
  - classic reference: Hampel (JASA, 1974)
- more general distribution results, review -- also mentions influence functions!
https://ocw.mit.edu/courses/economics/14-384-time-series-analysis-fall-2013/recitations/MIT14_384F13_rec12.pdf
http://faculty.arts.ubc.ca/pschrimpf/14.385/nonlinear.html
  mostly based on ...
- Newey-McFadden
  - discuss influence function in section 3

- asymptotic distribution of S^2
http://www.unc.edu/~hannig/STOR655/handouts/Handout-asymptotics.pdf

**** problem 4 in Keener chapter 5 -- UMVU estimator for ratio of variances of normal distributions

*** GMM
Duffee uses GMM and I'm trying to understand why

sources:
https://ocw.mit.edu/courses/economics/14-385-nonlinear-econometric-analysis-fall-2007/lecture-notes/notes_gmm.pdf
https://ocw.mit.edu/courses/economics/14-385-nonlinear-econometric-analysis-fall-2007/lecture-notes/lec13_gmm.pdf

[[http://larspeterhansen.org/wp-content/uploads/2016/10/Generalized-Method-of-Moments-Estimation.pdf][Hansen (2007) notes "Generalized Method of Moments Estimation"]]
- high-level overview but dense and somewhat technical

[[file:~/Papers/H/Hansen%20and%20Singleton%20(1982)%20Generalized%20IV%20estimation%20of%20Nonlinear%20Rational%20Expectations%20Models.pdf][Hansen and Singleton (1982)]]
- describe methodology to estimate RE models with GMM
- estimate simple CRRA model for stock prices
- quite a bit of evidence against this model, but different instruments lead to different results
- explain differences with MLE (which they use in their [[file:~/Papers/H/Hansen%20and%20Singleton%20(1983)%20Stochastic%20Consumption,%20Risk%20Aversion,%20and%20the%20Temporal%20Behavior%20of%20Asset%20Returns.pdf][1983 paper]])

** TODO [#B] How large is the random walk in interest rates?
- re-read Cochrane's paper and work through all the math
- calculate Cochrane variance ratios
**** TODO need confidence intervals

** TODO estimate the spectrum of yields and detrended yields
** TODO talk to Vasco about time-varying inflation target in macro models, non-stationarities
** improve estimation for Section 7
- automatic bandwidth selection
  - available in sandwich R package
  - described in detail in [[file:~/Papers/A/Andrews%20(1991)%20Heteroskedasticity%20and%20Autocorrelation%20Consistent%20Covariance%20Matrix%20Estimation.pdf][Andrews (1991)]]
- different kernel (QS)
- use knowledge/analytical results about persistence of conditional
  variances of h-period changes
- jointly estimate across horizons!
** CP/excess returns: OOS forecasting results; cycle factor
* brainstorming
- our own estimate of r* that can be used in this analysis
  - UC model a la Stock-Watson for ex-ante one-year real rate
    - SPF for inflation expectations
  - importantly, this doesn't use information in long rates
  - more general model for r* would allow inflation expectations to
    deviate from survey
- extended model for pi* and r* but without yields
  - still goal is to estimate r*
  - include lots of survey information on inflation
  - could be used to forecast/estimate the short-rate path
- should we try to answer our question in one coherent empirical
  framework, a model to test our hypotheses?
  - estimates persistence of inflation cycle and real-rate gap
  - tests hypothesis whether there is time variation in r*
  - other hypothesis: there is no trend in the term premium

- these approaches use fully specified UC/state space models,
  estimated either with MLE or, more likely, with MCMC
- that's also more generally what I want to get back to
  - that's where I have an edge -- computing/time series econometrics,
    my thesis used these tools
  - establish myself as expert in not only DTSM models but time series
    models more generally

- first step: Stock-Watson UCSV model on inflation (replicate their
  resutls) then ex-ante real rate
- then expand to include AR(1) gap, then joint model for multiple
  series

- ultimately we want a DTSM model that we believe in
  - incorporates/generates plausible pi* and r* series
  - definitely unit root under P
  - under Q either unit root or close to one
  - maybe allow for stochastic volatility
- have TP estimates and r* estimates available online for everyone to download!
  - right now there are no Bauer-TP estimates available
  - not even FRBSF estimates at all online

* Cieslak-Povala
** what kind of MTSM can replicate their and our findings?
standard model vs. shifting-endpoint model
- unspanned JPS/PC model with (YoY) Core CPI inflation as macro factor
- unspanned model where level of yields is cointegrated with trend inflation

- spanned model with multiple level factors

- not only replicate CPo's evidence but also fix it?!
  - Similar to DPY(i) and DPY(ii)

** CP results sensitive to initialization of EWMA
method: initialize first observation of inflation, then EWMA recursion
with their value of v
- sample period used for regression is Nov-1971 to Dec-2011, but for
  calculation of pi-star with EWMA, they started their sample in the late 1960s (see Figure A.2)

(a) if sample starts in 1968 then R^2 = 53%  -- this replicates their results
(b) if sample starts in 1962 then R^2 = 42%
(c) if sample starts in Nov-1971 then R^2 = 40%

if (c) and monthly CPI then R^2 = 38%

note: this would seem to suggest that the results are driven by
observations early in the sample, since those are the ones affected by
initialization of the filter. to understand this:
- compare pi-star series with different initializations
- are results in post-1987 period affected?

hunch: there must be some econometric issue that drives these huge
R^2, which makes R^2 a random variable with a high mean

** TODO CPo's term structure model
-> simulate from it
overarching goal: show that such a model cannot generate their
predictability of excess returns, even if you add measurement error to
break spanning

*** DONE under EH as described in their section 2.5
- I get distributions of R^2 that are generally lower, in particular
  with lower persistence
  - their results -- Table 2, Panel B -- are probably wrong: they
    barely change at all with persistence of predictors!
- but it could also be that scaling/frequency play a role
  - monthly vs. annual mean-reversion parameters
    - section 4.3 indicates that .975, .75 might be annual mean
      reversion parameters, so monthly would be .975^(1/12)~=1
  - assuming that the given phi's and SDs are annual and rescaling
    them to monthly I get much closer to their results

*** DONE replicate results on model calibration in section 4.3
- see whether I get similar parameters
- understand their model perfectly well
- goal: use their model parameterization for simulation
*** DONE replicate their results on measurement error in section 4.4

*** TODO unrestricted model - is it consistent with the regression evidence?
- PCs capture most of the predictive power, dR2 on average 3.5%
- when using just y1 and ybar, dR2 can be larger, around 11%

open issues:
- simulate monthly sample (currently annual)
  - use same loadings but translate annual time series parameters into
    monthly
- judge whether this captures predictive power in the data
- if not, describe why not

*** TODO calculate fitted yields
* Relevant literature
** TODO Cogley, Timothy. (2005) “Changing Beliefs and the Term Structure of Interest Rates: Cross-
Equation Restrictions with Drifting Parameters.”Review of Economic Dynamics,8,420–51.
** TODO Piazzesi-Schneider "Trend and cycle in bond premia"
  - "A typical finding [in the term structure literature] is that
    deviations from the expectation hypothesis can be smaller if
    expectations of future interest rates are computed under a
    learning scheme"
** TODO Chun (2010, RFS) Expectations, bond yields, and monetary policy
- Jardet-Monfort-Pegoraro
** Lettau and Van Nieuwerburgh (2007) Reconciling the Return Predictability Evidence
** term structure models with real and nominal yields
*** Buraschi-Jiltsov (2005)
- equilibrium RBC model -> real and nominal term structure
- link up with affine model

- "monthly observations from January 1960 to December 2000" and
  "Inflation data are based on the Consumer Price Index (CPI)"
  - one of the few studies using monthly inflation

- judging from Fig. 1 they are using y-o-y CPI inflation
  - but they are not concerned with autocorrelation, persistence, or unit
    roots, and not bothered by overlapping observations

*** Campbell-Viceira (2003) Who should buy long-term bonds
discrete-time, two-factor homoskedastic model that allows for nonzero cor-
relation between innovations in the short-term real
interest rate and innovations in expected inflation
- assumes that inflation risk premium is constant
  - Ang-Bekaert-Wei's model "I_w" is the same but with time-varying
    IRP

- use quarterly data inflation "in order to reduce
the influence of high-frequency noise in infla-
tion and short-term movements in interest rates"

*** D'Amico, Kim, Wei - Tips from TIPS

- sample yields weekly, observe CPI once a month
- specify model in log of price level

*** Ang, Bekaert, Wei (2008) Term Structure of Real Rates and Expected Inflation

- "similar to Campbell and Viceira (2001), we sample all data at the
  quarterly frequency."

*** Chernov and Mueller (2012) The term structure of inflation expectations

- quarterly time series of log changes in seasonally adjusted CPI

** shifting endpoints in interest rates
- Orphanides-Wei (2012, JEDC)
*** Kozicki-Tinsley (2001)
- nominal rate endpoint is long-horizon expectation of nominal short
  rate
- they use constant risk premium
- hence endpoint is infinite horizon forward rate minus constant
*this is unappealing -- need risk premium estimate*
- need long-term inflation expectations to estimate real-rate endpoint
- L-W: they "use forward rates implied by the term structure and a
  measure of inflation expectations to estimate low frequency
  movements in the natural rate of interest"

*** Dewachter Lyrio (2006, JMCB) most cited
- all of these are completely reduced-form
  - no IS curve, Phillips curve, etc
- extend Kozicki-Tinsley
  - shifting inflation endpoint and real-rate endpoint in the model
  - time-varying prices of risk
- basically cointegration model -- VECM
- data: only interest rates and inflation and output
  - output gap using HP filter
- slow-moving endpoints

*** Dewachter, Lyrio, Maes (2006, JAE) second-most cited
*** Dewachter and Lyrio (2008, NBER Macro Annual)
*** Dewachter and Iania (2011, JFQA)
- similar but discrete time
- Bayesian estimation
- includes survey data on inflation expectations
- CBO potential growth identifies the equilibrium real rate
- impose linear relationship between potential growth and r*
  - but deviation is IID!
- inflation endpoint varies strongly over time
- eqbm real rate is *very* stable over time (similar level as mean
  L-W estimate)
  - presumably because driven only by potential growth
  - much more stable and less interesting than L-W natural rate
*** Dewachter, Iana, Lyrio (2014, JAE)
uses same model as in Dewachter and Iania (2011)

** persistence of interest rates
Ball and Torous (1996) show that interest rates exhibit near unit root
behavior, which causes small-sample bias

"Research beginning  with Nelson and Plosser (1982) indicates  that many macro-
economic  time series such as interest  rates and inflation  may be characterized  as
having  stochastic  trends."  (quote from Mishkin, 1992)

Campbell and Shiller (1987), Stock and Watson (1988)
- cited in Wallace and Warner (1993)

Rose (1988) finds nominal rates to be I(1)
"the literature clearly indicates that the nominal interest rate is
nonstationary" (Rose, p. 1098) with references to Fama, Fama and
Gibbons, Mankiw and Miron

** relationship between interest rates and inflation / persistence of real rates
Neely and Rapach (2008) survey article on real interest rate
persistence / cointegration tests

Rapach and Weber (2004) "Are real ineterst rates really nonstationary?
New evidence from tests with good size and power"
- use state of the art unit root and cointegration tests

- early work: [[../Papers/F/Fama%20(1975)%20Short-Term%20Interest%20Rates%20as%20Predictors%20of%20Inflation.pdf][Fama (1975)]], [[../Papers/F/Fama%20and%20Schwert%20(1977)%20Asset%20Returns%20and%20Inflation.pdf][Fama and Schwert (1977)]]

[[../Papers/R/Rose%20(1988)%20Is%20the%20Real%20Interest%20Rate%20Stable.pdf][Rose (1988, JF)]] "Is the real interest rate stable?"
- seminal paper that started this whole literature
- finds nominal interest rates to be I(1) and inflation to be I(0) and
  hence concludes that the real rate has a unit root

[[../Papers/M/Mishkin%20(1992)%20Is%20the%20Fisher%20effect%20for%20real.pdf][Mishkin (1992)]] "finds no support  for a short-run  Fisher effect in which a change  in expected  inflation  is associated
with a change  in interest  rates. but supports  the existence  of a long-run  Fisher  elect  in which
inflation  and interest  rates have a common  stochastic  trend when
they exhibit trends. "

[[../Papers/W/Wallace%20and%20Warner%20(1993)%20The%20Fisher%20Effect%20and%20the%20Term%20Structure%20of%20Interest%20Rates-%20Tests%20of%20Cointegration.pdf][Wallace and Warner (1993, REStat)]] "The Fisher effect and the term
structure of interest rates: Tests of cointegration"
- "virtually all Fisher effect studies have limited themselves to the
  relation- ship between short-term interest rates and short-tcrm
  inflation"
- "we provide support both for the exis tence of a Fisher effect on
  short- and long-term interest rates and for the expectations theory
  of the term structure of interest rates"
- With only one exception, we are unable to reject the restriction
  that the cointegrating vector is [1, -1].
- Atkins (1989) is an exception in finding consistent cointegration
  relationship -- others either find none (Rose) or one that is
  dependent upon the time period (MacDonald and Murphy)

[[http://www.sciencedirect.com/science/article/pii/S0304393299000173][Koustas and Serletis (1999, JME)]] ""On the Fisher effect"
 apply the King and Watson (1997) (integration, cointegration)
methodology and conclude that "the data are generally rejecting the
fisher effect"
- first they carefully investigate order of integration and
  cointegration of inflation and interest rates in different countries
- find for almost all countries that both are I(1) but cointegrated
- then they dive into the King-Watson-type analysis, which is very
  different from cointegration

[[../Papers/K/King%20and%20Watson%20(1997)%20Testing%20Long-Run%20Neutrality.pdf][King and Watson (1997)]] "Testing long-run neutrality" consider
methodological issues of testing long-run neutrality when the
variables are integrated.
- long-run Fisher effect: permanent changes in inflation have no
  effects on real interest rates
- "In contrast to these papers, our results are predicated on the
  assumption that π t and R t are I(1) and are not cointegrated over
  the entire sample" (fn. 11)
  - Evans and Lewis (1993), Mishkin (1992), Mehra (1995)
- "evidence against the long-run Fisher relation is not overwhelming"
  (p. 89)

[[../Papers/E/Evans%20and%20Lewis%20(1995)%20Do%20Expected%20Shifts%20in%20Inflation%20Affect%20Estimates%20of%20the%20Long-Run%20Fisher%20Relation.pdf][Evans and Lewis (1995, JF)]] Do Expected Shifts in Inflation Affect Estimates of the Long-Run Fisher Relation?
- existing evidence that real rates are subject to permanent
  disturbances is puzzling
- inflation does not move one-for-one with the nominal rate in the
  long run.
- they introduce regime-switching model to reconcile data with Fisher
  hypothesis
  - "rational anticipations of infrequent shifts in the inflation
    process" lead to small-sample bias in estimates of LR Fisher effect

[[../Papers/C/Crowder%20and%20Hoffman%20(1996)%20Fisher%20Equation%20Revisited.pdf][Crowder and Hoffman (1996, JMCB)]]
- clearly explains the evidence on short-run and long-run Fisher
  effects including three key papers (Rose, 1988; Mishkin, 1992; and
  Evans and Lewis, 1995)
- gives a nice overview of the econometric issues involved-
- Novel results, based on *Johannsen's MLE approach*, support (a)
  cointegration, and (b) one-for-one response of nominal interest
  rates to inflation in the long run.
- This is strong evidence for the long-run Fisher effect.
- The authors also specify a VECM and demonstrate that interest rates
  adjust to the equilibrium but take a long time to do so. This is
  directly in line with Cieslak and Povala.
Some key takeaways for me are:
- These findings seem to be completely ignored in the term structure
  literature, as well as by CPo.
- This paper justifies some of the assumptions of the simple VECM I
  have been working with, including cointegration of interest rates
  with pi*.
- We probably don't need to include any cointegration analysis in our
  paper, since we can just reference these findings.
- Since this line of research assumes a stationary real-rate /
  constant r*, it may be interesting to confront it with a world in
  which long-run r* moves around.

[[../Papers/I/Ireland%20(1996).pdf][Ireland (1996)]]
investigates Fisher hypothesis and finds that "according to Lucas’s model, movements
in the long-term bond rate primarily reflect changes in long-term inflationary
expectations"

[[https://books.google.com/books?id%3Dxe7NDY8leWwC&pg%3DPA86&lpg%3DPA86&dq%3D%2522Vector%2BAutoregressive%2Band%2BVector%2BError%2BCorrection%2BModels%2522&source%3Dbl&ots%3D_95d-5qV9s&sig%3Dr7Sg-f8w1bOFLgYvHXmLimiY8a0&hl%3Den&sa%3DX&ved%3D0ahUKEwjIoN2_jOnKAhUJ_mMKHYLNDtQQ6AEIRjAI#v%3Donepage&q%3D%2522Vector%2520Autoregressive%2520and%2520Vector%2520Error%2520Correction%2520Models%2522&f%3Dfalse][Luetkepohl (2004)]] "Vector Autoregressive and Vector Error Correction
Models" analyzes the cointegration relationship between German long-term interest rate and quarterly
inflation rate

[[http://www.scienpress.com/Upload/JAFB/Vol%25202_6_4.pdf][paper by Turkish authors]] contains many references

** term structure models
- Golinski and Zaffaroni (2016) try to solve the problem using
  fractional integration
- Monfort, Pegoraro, et al - near-cointegration
- Gil-Alana and Moreno (2012, JBF) fractionally integrated model for
  short rate
* yield-curve model with shifting r* and pi*
- main goal: have a working endpoint model for the U.S.
  - reasonable properties for r* and pi*
  - good yield fit
- understand how inclusion of survey expectations changes estimates of
  endpoints
** Bayesian estimation
- get confidence bands for r-star!
- and use block-wise algorithm where we just use
  1) regressions in one block
  2) filtering of unobserved states in other block
- competitive advantage: few other people can efficiently do this
- can easily deal with pile-up problem for trend component

** multi-country model !
** make a truly international version of Laubach-Williams ?
- their estimates are ad hoc--just LW for each country, no connection!
John:
- need to make it an open-economy version
  - add real exchange rate to the IS curve
  - if anything, Euro-area is most similar to US
- want to estimate global and local factor of r*
- issues with ECB's inflation series
  - need to splice their harmonized mean together with previous series

** Taylor rule
  - naturally implies Taylor rule estimates
  - presumably differs from Taylor rule that implicitly assumes
    constant r-star

** term premia
- endpoint-model should lead to much more plausible long-horizon
  risk-neutral rates than stationary affine model (where they are
  basically constant)
  - consequently more plausible term premia

** variance decompositions in DRA
- what were DRA doing?
- what is the role of the Cholesky ordering?
- what exactly does a variance decomp tell us about covariances of levels/changes?

** simple MTSM with observed risk factors
- risk factors: trend inflation, level/slope of yield curve
  - maybe include: inflation, r*, real rate
- variance decomposition
  - short-run vs. long-run?
  - levels vs. changes?

easy:
- try different endpoints for inflation
- also include endpoint for real rate
- Nelson-Siegel instead of PCs

more involved:
- *no-arbitrage model*
- estimate pi* as part of the model
- estimate r* as part of the model

lower priority:
- allow non-zero mean for stationary variables


*** compare to ACM
1. reproduce ACM term premium
   - either use simple PC model
   - or use their no-arbitrage model
   - try to match their (monthly) series as closely as possible!

2. then assess effects of shifting endpoint for level factor
   - for 10y yield term premium
   - for 5-10y forward term premium


**** sources
- download TP
https://www.newyorkfed.org/research/data_indicators/term_premia.html
- description
http://libertystreeteconomics.newyorkfed.org/2014/05/treasury-term-premia-1961-present.html#.Vl-VCFWrRaQ
- correlation with various variables
http://libertystreeteconomics.newyorkfed.org/2013/04/do-treasury-term-premia-rise-around-monetary-tightenings-.html

* first simple shifting-endpoint MTSM a la Dewachter et al
** Kalman filter
Kalman filtering in R: http://core.ac.uk/download/pdf/6340262.pdf

*** gradient and information matrix

http://interstat.statjournals.net/YEAR/2013/articles/1301001.pdf
algorithm for the exact construction of the score

*** DONE non-invertible V - cannot evaluate Kalman filter for reasonable starting values
  - prediction error variance is not positive definite (up to
    numerical precision)
  - issue arises if variance of measurement error is too small (<1)
  - reasonable values--for usual scaling--would be (10/120000)^2

- what if measurement errors are zero?
  - then V has rank 5?

**** square root filter

http://www.gamedev.net/topic/647764-kalman-filter-without-using-matrix-inverse/
https://en.wikipedia.org/wiki/Kalman_filter#Square_root_form

Schneider -
http://www.sciencedirect.com/science/article/pii/089812219290183I -
advocates the use of the square-root filter, and uses it in a Bayesian
context for an FFSB algorithm
discrete square-root filtering --
http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1099816 (paid)


could use dlm package which implements square-root filter
 (I've also used this package in the past)

BUT: it might not be an issue that's solved by using square-root
filter -- my INITIAL covariance matrix is already non-invertible
 - scaling might be a better choice

**** what I learned:
- it matters a lot what the initial condition is!

initial conditions:
http://as.utia.cz/publications/2007/Suz_07.pdf
http://www.jstor.org/stable/2965434

my solution: do like Hamilton suggests: analyst's best guess -- use
observations of proxies/macro vars in first quarter, and their sample
variance as measure of uncertainty

** EM algorithm
https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm

Dempster-Laird-Rubin http://www.jstor.org/stable/2984875

step-by-step instructions for MLE of Kalman filter with EM algorithm:
http://arl.cs.utah.edu/resources/EM%20Algorithm.pptx

application of EM algorithm, and more references
http://www.cs.ubc.ca/~emtiyaz/papers/TBME-00664-2005.R2-preprint.pdf

excellent, concise overview of the steps and formulas involved
http://webber.physik.uni-freiburg.de/~jeti/papers/1-s2.0-S0096300314006869-main.pdf

implementation in R
http://artax.karlin.mff.cuni.cz/r-help/library/astsa/html/EM1.html

Shumway & Stoffer - complete book
http://www.stat.pitt.edu/stoffer/tsa3/tsa3.pdf
EM algorithm on page 344

** optimization
*don't spend too much time on it because next is Bayesian estimation*

Nash resources:
http://www.wiley.com//legacy/wileychi/nash/resources.html?type=SupplementaryMaterial

*** DONE try different methods
  - BFGS
  - L-BFGS-B
  - CG -- as implemented in Rcgmin
  - *stochastic optimizers*

*** TODO try different starting values
random starting values

**** TODO choose starting values that don't violate stationarity constraints
- 78 out of 101 are not stationary in my first attempt for est_simple_lambda.r

**** TODO which starting values lead to warnings in kalman filter? choose smarter!

*** numerical derivatives
- make sure derivatives for gradient and Hessian
  - use the right step size (Nash p. 127)
  - are robust to change in settings (simple vs. Richardson)

*** Hessian conditioning
  - is it parameter scaling?
  - or accuracy of numerical derivatives?
  - look at diagonal of Hessian -- own second derivative

*** Simple axial search around solution
  - changes in function value
  - first and second derivative

*** optimx
http://www.jstatsoft.org/article/view/v043i09/v43i09.pdf
- first few methods successful
  - BFGS just needs more iterations (itnmax>100)
- KKT2 not successful
  - Hessian somewhat badly scaled but may not be a problem
  - make sure to separately check (a) eigenvalue sign, (b) ratio of eigenvalues

can look at details using
 attr(arb, "details")["BFGS", "nhatend"]
or, simpler, using utility function "get.result" -- see ?optimx

** TODO alternative estimation: Hamilton-Wu vs. Adrian-Crump-Moench

** TODO identification - think hard about what the canonical model is

** TODO role of inflation survey data - how do they change pi*/r* ?

** additional results to look at
*** violations of the ZLB?
*** DONE VECM parameters under Q and P -- properties of series and endpoints
*** estimated Taylor rule

** extensions

## NEXT
## - estimate with alternative risk-price specification
## - what is the maximally-flexible version of the model
##   - what if I want to impose that P and Q endpoints are (a) the same, (b) differ by only a constant
## - how about introducing a wedge (additional factor) between P and Q endpoints?
## - intercepts/weak EH
##   - what is the average level of the term premium?
##   - how can we impose the weak EH in the model estimation (without imposing strong EH)

- restrictions on risk prices?!
  - what restrictions, relative to canonical model, are supported by
    the data?

- can I force endpoints to be smoother?

- make more flexible to fit both nominal yields and inflation
  expectations

- use Bayesian estimation
- use data back to beginning 1960s as in Dewachter papers
- missing values -- methodology can deal with this
  - estimate monthly model
- include more survey data

** *main issues so far*
a number of issues with estimation and possibly with identification
- only simple and simple_EH give moderately reasonable results
  - but still not very plausible r* and pi* - very volatile
- all other models give highly implausible results
  - large gradients, negative Hessian eigenvalues, noninvertible
    Hessian
- stationarity constraints
  - unconstrained estimation achieves lower LLK! -> clearly local optima
** TODO idea: different rP* and rQ*
- allow these two to be different
  - in a very flexible way, and not only by a constant or determined
    by other observable risk factors
  - need this flexibility to have term premium in long-term real
    forward rates
- open question: how does simple Dewachter model constrain the
  difference between rP* and rQ*?
- what identifies rP* in a very flexible model?
  - in a stationary model, it's basically just the average real rate
  - in a VECM model, with latent rP*, it's a filtered trend
    - similar to trend inflation model!
- what does this model need to look like?
  - under Q vs. under Q?
- possibly use risk-price restrictions to use /some/ information in
  real forward rates to inform estimate of rP*
- make sure to distinguish inflation/real-rate endpoint from latent
  variables r* and pi*
  - they differ unless r* and pi* are simple random walks

** double-check current specification (lambda calc, etc)
** multiple starting values
- use better starting values - currently most are invalid, lots of
  warnings
- identification: check whether those maxima that have similar/equal
  LLK actually have the same parameters!

** consolidate data and code
- have one big macro data CSV file (quarterly)
  - all my macro variables, including proxies for r, r*, and pi*
- and one big yield data CSV file (could be monthly)

- combine in one estimation script
  - both preliminary estimation using proxies and actual estimation
    - do over same sample period
  - estimation using different data series samples
  - different measurement equations (PTR vs. SPF)
  - different specifications for Sigma, alpha, lambda

-> modularize! avoid redundancies

** model without output gap per Glenn's suggestion
** Bayesian estimation
** JLS/JPS type of model with moving endpoints?
** survey data
find out more about what survey information we have
  - Consensus Economics
  - how far back to we have Bluechip?

* our new MTSM - PCs and inflation with unspanned trend
purpose: estimate the interactions between yields and pi* and r* in
order to answer these questions:
- is there a one-for-one response to pi* as in the long-run Fisher
  hypothesis?
  - if not what is the response?
- how much of the secular increase and decrease in yields was due to
  shifting macro trends?
- how does accounting for shifting trends change the estimated
  dynamics of the term premium?
** model that treats pi-star observable
simple endpoint model apparently cannot generate the predictability we see in the data
while non-stationary VAR can generate it

Make sense of these results!

questions about first set of results
- Why are small-sample Delta-R2 so small?
- Why are large-sample Delta-R2 very big and variable?
- Why does demeaned model give larger Delta-R2?

*** ideas
- check whether I am doing everything right
- Other DGPs to try
  - more general cointegrated model - more lags
- look at simulated series
  - do pistar and ybar have a common trend?
  - are yields (ybar) reverting back to pistar?
  - which series has partial adjustment? how fast is partial adjustment?
- simulate 1000 series for T=100,200,500,1000,2000,5000
  - what happens to distribution of Delta R^2?

*** Observations and answers
look at moments of all variables:
- pi-star is substantially less variable than in the data
  - pi-star is very smooth, first difference is not very volatile
  - treating pi-star as a random walk is wrong: first difference has
    high serial correlation!
- better model:
  - inflation is local trend model (UC + white noise) or UC + AR(1)
    - need to estimate from observed inflation data
  - we observe inflation and construct EWMA - or we directly observe
    trend - to get predictor pi-star

** model in which L is cointegrated with latent pi*
this can generate CPo results (CIs cover delta.R^2 in the data)
*** results getSEmodel()
- Delta R^2 of up to 25%
  - LLK 2176.8
  - trend very similar too UC trend
  - beta1 estimated around 5
  - yields and inflation too variable (factor 1.5)
  - pi-star too variable (factor 3)
  - ciresid too variable (factor 4.5)
  - if I impose beta1=(0,0,0) then Delta R^2 drops to (0.0; 0.17)
*** results getSEmodel3ect()
- Delta R^2 of up to 27%
  - yields too variable by factor 2
  - pistar too variable by factor 3
  - LLK 2171
  - if I impose beta1=(0,0,0) then Delta R^2 drops to (0.0; 0.15)

*** DONE estimate SE model with yields and inflation using Kalman filter
key questions:
- match moments in the data?
  - yes, similarly well as model with two-step estimation

- what does the filtered pi* look like in comparison to UC model?
  - very similar

- parameter estimates vs. two-step model?
  - Psi nearly non-stationary, whereas in two-step estimation it's
    stationary
  - cointegration vector: quite different from two-step
    estimates. somewhat more persistent than a priori coint vector

**** Kalman filter estimation -- near non-stationary Psi
symptom: Hessian is not positive definite/gradient-based optimization doesn't work
- reason: eigenvalue restriction -- beta'X_t
  (had similar problem with est_simple.r)
- at optimum, max.ev. is nearly one

- oddly, OLS VAR for beta'Xt does not give eigenvalue that is near one
  - and if LLK is evaluated at OLS values for alpha, it is much, much
    lower -> Kalman-filter/LLK does not like stationary beta'Xt
- but VECM with given coint. vector and states from Kalman filter
  gives Psi that is explosive!
  - with estimated coint. vector it gives the same results as two-step
    estimation (because filtered states similar)
  - with *given* coint. vector it gives explosive eigenvalues

-> why do OLS for beta'X_t and VECM give different results?
   - maybe warning sign that OLS and VECM estimates are so different

-> why does Kalman filter choose cointegration vector that
cointegration residual non-stationary?

but apparently this does not make a difference for CP results, as both
two-step estimation and Kalman-filter estimation give similar results

ideas:
- research "VECM and Kalman filter"
- consider EM algorithm?
  - Shumway and Stoffer (ftp://sunsite.univie.ac.at/mirrors/lib.stat.cmu.edu/general/tsa/em.pdf)
  - to understand optimal parameters conditional on filtered states
  - these are not identical to just OLS using filtered states


**** correct initialization of Kalman filter
   - for slope and curve, should use unconditional var

*** DONE fix estimation -- figure out why MLE wants non-stationary beta'Xt
- note that when beta is fixed and beta_0 = 0 there is no problem
*** DONE estimate model that imposes cointegration vector a priori

*** DONE compare term premium estimates to existing ones

** model with common trend in yield factors and inflation
*** CT-model
- baseline results - inflation gap is AR(1), no noise
  - gamma1 -- coefficient on trend in level
    equation -- is much too low, and trend (as usual) is much too
    variable
  - delta R^2 lower than with SE model
  - predictability generally quite low
  - regressions with filtered trend (whether UC or CT) generally have
    about 1/3 to 1/2 the DR^2 as with EWMA trend
- if signu2 is fixed to small value, then estimation results
    look good. otherwise
  - but only with normal/MLE signu2 do we get enough predictability,
    match other moments in the data
    - small RW makes EWMA pistar much too stable -- why?
    - compare var(pistar) and var(pistar.filt.se)
  - we obviously want both (a) smooth pi* and (b) match moments in the data
- AR(4), with noise, tau=.01
  - predictability of returns very low
  - but moments of yields and inflation overall matched pretty well
  - predictive regressions in the data
    - for xr.avg, and for dPC1 with ybar and y1, CT trend does not
      work, only UC trends and EWMA trend (same DR^2 since for tau=.01
      the UC trend is very similar to EWMA trend)
      - this indicates that incorporating yields distorts the trend --
	use separate trend!
    - for dPC1 with PCs, as predictors, CT trend actually works
      - this is puzzling
    - different than for AR(1) model
  - if I impose spanning, Delta^2 falls to half its previous value
  - here R^2 results for dPC1 are somewhat surprising
    - Model - EWMA - pi* has zero coefficient and low R^2
      - this correponds to main (negative) result for excess returns
    - but true trend gives about as much R^2 as in the data
      - surprising because previously this didn't make much of a
        difference
  - R^2 results for xr.avg (using PCs) are very clear
    - in the data, CT filtered trend doesn't work whereas UC trend does
    - in population and in simulation, Delta R^2 pretty small
    - in population/long sample R^2 seems to diverge
  - R^2 results for P1(t+h)-P1(t) similar to xr.avg
    - except for in population, R^2 doesn't diverge anymore
    - in long sample, coefficient on EWMA pi* is small, coefficient on
      true trend pi* is large (and consistent with my calculation),
      but *in both cases var(Ey) remains very small*
- Why is var(Ey) so small relative to the data?
  - even if coefficient on pistar is large. must have to do with large negative coefficient on level which
    offsets this

- AR(2), tau=.01, sig2=0
  - LLK -2176.74
  - CT trend very close to EWMA and UC trend
  - regression results with CT trend in the data look great
  - BUT: model-implied predictability still no bueno


- if tau is left free in some cases it's estimated around 0.015
  (nice), but for AR(4) tau^hat = 0.36

*** 2T-model
model with separate trend in yields (similar to Mertens)
- yield trend ends up being zero -- pile-up problem -- so same results
  as for CT-model

- LLK with TAU=.01, free sigz2
- p=4, TAU=.01, SIG2 free, SIGZ2=.01
  - LLK 2148.7
  - gamma1 reasonably large (5.8)
  - CT filtered trend reasonable but still more volatile than UC trend
  - trend has some predictive power but still quite a bit less than UC trend
- SIGZ2=.1
  - LLK 2151
  - gamma1 really small!
  - crazy trend

** comparing the models
*** SE-model
 - beta1 = (5.1, 0, 0)
 - LLK -2177.127
 - Delta R^2 (0, 0.25)
 - yields and inflation too volatile
 - estimation doesn't work well - near non-stationary
*** SE-model 3ect
 - beta1 = (5.1, 0.2, 0)
 - LLK -2170.86
 - Delta R^2 = (0, 0.27)
 - but R^2 only means .11, .18
 - yields *much* too volatile
 - estimation works well
 - largest eigenvalue is 0.975
*** CT-model
 - gamma = (1.2, -.2, .1)
 - LLK -2162.743
 - largest eigenvalue of phi is 0.994
 - fits yield variances accurately
 - estimation works well
 => seems to be much preferable

*** CT model seems preferable but SE model gives higher predictability

*** why are beta1 from SE model and gamma from CT model so different?
- beta0 quite different too
- maybe because for CT model gamma also affects variance?
probably not that important since CT model is the right one

*** imposing spanning
- if I simulate in model where spanning holds (gamma=0)
- CT model, AR(1), tau free, no noise
  almost the same results for R^2 and moments
  - actually R^2 even a little bit higher in that case
  - gamma was small anyways
- SE model
  - Delta R^2 has higher distribution (0,0.24) with non-zero beta1,
    with spanning it's only (0, 0.17)

idea: might need to re-estimate the model under the restriction that
gamma=0 to really gauge the effects of this restriction

** CT model with non-zero correlation between pistar shocks and cycle shocks
- p=1, tau=free, sig2=0
  - CI contain Delta R^2
  - gamma = 5.7, .2, 0 -- nice!
  - matches a lot of moments!
  - LLK -2157
  - quite variable trend
  - rho=.07 --- basically local level model
  - tau=.3
  - tau identified cleanly - same for all starting values in UC model!
- p=1, tau free, sig2 free
  - LLK -2137
  - rho = 0.9
  - tau = 0.024  - but very different for different starting values
  - Delta R^2 too low
- p=2, tau free, sig2 free
  - LLK -2156
  - ends up being local level model
    - sigv2=0, tau huge, signu2=0.3, sig2=2.5 -> *RW + NOISE*
  - with true trend I can match d.R^2 of dPC1
    - though A and B too large, A^2/B/C is about right
  - with EWMA trend I get at least the CI for d.R^2 for dPC1
  - same with EWMA and xr.avg
  - with true trend and xr.avg: I am getting Delta R^2 right on
    average!
- p=4, tau=.01, sig2=free
  - LLK -2134
  - d.R^2 too low, even with true trend
- same with free tau
  - LLK -2148 - local optimum
  - rho very small, sig2 about 0 -> local level model
  - tau = 0.34
  - again, with true trend I get d.R^2 right for both dPC1 and xr.avg

** CT model with survey data to pin down inflation
- p=1, sig2 free
  - very small sigs2 -- takes surveys as exactly pi*
  - LLK -2406
  - rho is pretty high - nice - 0.91
  - signu2 is pretty low - 0.01; sig2 around 2%
  - CI for d.R2 covers data, but mean d.R2 only 13% of data
  - using true trend, can exactly generate results in the data!
- using y-o-y inflation data
  - still pretty reasonable results
  - sig2 very small, sigs2 .004
  - with EWMA trend can't quite generate predictability in the data
    since d.R^2 is 28.6 and CI only goes up to 21.8%
  - with true trend can about match the results (70% of d.R^2)
- if I impose that sig2=0 before simulation
  - in simulations CI for d.R^2 is higher
- if I impose higher measurement error for yields
  - little to no effect

** possible model extensions
- try other data
  - monthly but y-o-y inflation
  - quarterly data set
- VAR for all gap components - (c_t, g_t)
- VARMA(1,1) for cycle
  - d.PC, d.y aren't matched at all!
- VAR(12) for cycle
  - would need to use two-step estimation
  - this could help with excess returns
  - but we also are having trouble with one-step ahead forecasts!

** TODO understand R^2 in model vs. data
work out which moments and model parameters determine Delta R^2

- unrestricted fitted values always too stable
- restricted fitted values (yields only)
  - for xr.avg not variable enough -> first-order Markov model
    generally can't generate a lot of predictability of annual excess returns
  - for dPC1 too variable (twice as much as in the data)

*** dPC1, one step ahead
- data: level/pi* coeff and R^2 for EWMA-pi* much higher than for filt-pi*
- baseline model -- AR(1), free tau
  - in population gives very small numbers (verified using one
    long simulation, using true trend)
  - in simulations, generates some variability of expected
    returns, median almost as much as in the data, but this is all
    from PCs, not from pi*
  - (it makes little difference for simulation results whether using
    true trend or EWMA)
  - overall quite similar results as for annual excess returns
  - tiny coefficients on pi*, centered around zero
  - Delta R^2 is simply due to chance
  - under spanning, coefficient on pi is exactly zero, no changes in
    Delta R^2
  => this model doesn't capture predictive power of pi* at all

*** DONE regressions with true vs. filtered trend
- with true trend
  - coefficients close to those in population
  - but Delta R^2 only very slightly higher in small samples

*** TODO other summary statistics - of stationary objects!
- moments that are matched well
  - most variances -- d.pistar, d.PCs, gap, level-cycle, curve-cycle
  - acfs of cycles, ciresid
- moments that are matched poorly
  - var(ciresid), var(slope-cycle)  much too high
  - cov(d.pi, d.PC1) much too high (surprising since var(d.pi) too low
    and var(d.PC1) about right -- this correlation must be way too
    high)
  - cov(d.pistar(t), d.PC1(t+1)) is of the wrong sign
  - ACFs of d.PCs and d.yields are far off
  - acf(gap) is somewhat too high

*** look at stationary moments in the model analytically
useful matrix result:
http://math.stackexchange.com/questions/17776/inverse-of-the-sum-of-matrices

*** in one case I can match Delta R^2 for dPC1
- model: p=6, TAU=.01, SIG2=NA
- use true trend as predictor
- but with filtered trend it doesn't work at all

*** DONE R^2 in balanced regression
- can't just regress return/change on P_t!
- Delta R^2 isn't a well-defined moment if yields are non-stationary
- include lags of predictors to have balanced regression
  - results are the same -- delta R^2 only about a tenth as high as in the data
- if I use first differences of explanatory variables R^2 is much
  lower in the data (ignores level of cycle)
** ideas/open points
  - allow for non-zero correlation between trend and gap shocks
  - random walk with trend in pi*?
  - fix gamma1 to value in the data
  - restrict gamma2,3 to zero
  - restrict rho to zero -- local level model for inflation
  - for given inflation trend, understand persistence of L-gap etc --
    is VAR(1) for cycle sufficient?
  - maybe the reason is that trend filtered from yields and inflation
    is not the relevant one
    - CPo found that trend from yields (EWMA) does not work
    solutions: allow for separate trend?
  - find out why SE-model works better for R^2
  - understand EWMA pistar vs. filtered pistar
    - compare both to true pistar in each simulated sample

** TODO contrast our results with stationary model
- a simple UMR model actually doesn't give too different d.R2, if
  somewhat lower than CT model
  - model: VAR for yields and y-o-y inflation
- for m-o-m inflation dR2 is a lot lower (since it doesn't pick up
  relation between yields and inflation)
  - that's not really fair to this model

** TODO no-arbitrage model
** TODO augment model to include r* -- filter from real rates
** TODO other testable implications of shifting-endpoint vs. stationary DTSM
- can we show that the data clearly rejects the stationary model in
  favor of a shifting endpoint model?
- this would be a strong justification for using this alternative type
  of model for term premium estimation and other purposes

- long-run forecasts
  - either as in Kozicki-Tinsley
  - or in-sample forecast accuracy
- ACFs, variance ratiors, measures of persistence
- term premia plausible?

* simple common trends model with r* and pi*
[2016-07-26 Tue]
** early ideas
- common trends model - two stochastic trends that drive the level of
  the yield curve
  - unspanned since yields determined by PCs but not by trends
  - not arbitrage free
- additional information on pi*
  - inflation surveys at short and long horizons
  - similar to Chernov-Mueller, but survey and real-world measure
    identical
- additional information on r*
  - potential growth/productivity growth
  - outside/external estimates of r*
  - surveys on long-run interest rate forecasts
- try both:
  - pin down trends with prior dispersion of permanent innovations
  - or by using additional survey/outside information
- consider stochastic volatility

** first simple specification in ct_simple.r
- further simplifications
  - no means of detrended yields
  - only TWO cycle factors
*** open issues for later
- loadings of yields on cycle are assumed to be PCs of cycles
  - based on PCs of preliminary estimates of cycles
  - no-arbitrage loadings would be better
- observed factors - shouldn't measurement error be reduced rank?
- specification ignores path of expected real rate and inflation
- restrictive assumption of orthogonal shocks to cycles and other
  variables

- deal with missing data using Kalman filter
- multiple series to pin down pi* and r*
- include simple LW block instead of outside estimates
- Bayesian estimation - choose priors and set up MCMC
- no-arbitrage loadings
  - (unspanned) DTSM for real and nominal yields with trends

*** factors in levels vs. cycles
- all based on pi*=PTR and r*Laubach-Williams
- detrend yields by simply substracting these
- PC analysis of demeaned yields vs. raw yields
  - level explains more of raw yields than it explains of demeaned
    yields
  - but that's because the variance of demeaned yields is already
    reduced by a factor of about six!
  - loadings look similar though - there still is level, slope,
    curvature
- probably need only one or two more factors in addition to endpoints,
  in order to explain the same amount of variation in yields as a
  three factor model for the level of yields
  - two PCs of raw yields have RMSE of 22bp, whereas for detrended
    yields it's only 10bp
  - three PCs similarly give around 2-3bp in both cases
=> could get better if pi* and r* estimates are also informed by
yields
=> for now work with model with 2 factors (but keep code flexible)

** Kalman filter with missing observations in ct_simple2.r
- filtered values for r* are enormously different
  - large measurement errors
- yield fit slightly better
  - presumably because r* is used to fit yields
- filtered level factor is now very persistent
  - largest eigenvalue close to one

How to better understand this?
- could force measurement error to be smaller
  - how does it affect likelihood and yield fit?
  - how about in the case of model with interpolated r*?

- first go ahead and include multiple estimates of r*, see what that gives

- is it really missing?
  - just re-using the same value three times seems reasonable as well

** TODO include additional r* series in simple model
include:
- Johannsen-Mertens filtered
- Laubach-Williams filtered
- moving average of real rates

** is this model spanned or unspanned?! compare to previous model

