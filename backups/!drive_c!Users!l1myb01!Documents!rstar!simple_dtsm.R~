## estimate simple DTSM with MLE
## - specification as in our trends paper (version June 2017)
## - goals: estimate r* from the yield curve

rm(list=ls())
source("R/fns.R")
graphics.off()
options(error=recover)

## load yield data
df <- read.csv("data/yields_gsw_monthly.csv")
yield.cols <- c("y0.25", "y0.5", paste0("y", c(1,2,3,5,7,10)))
mats <- c(3, 6, 12*c(1,2,3,5,7,10))
## yield.cols <- paste0("y", c(1,2,3,5,7,10,15))
## mats <- 12*c(1,2,3,5,7,10,15)
df <- df[c("Date", yield.cols)]
## df[yield.cols] <- df[yield.cols]/1200  ## per month, decimal
df$yyyymm <- floor(df$Date/100)
df <- subset(df, yyyymm >= 197111)
df$Date <- as.Date(as.character(df$Date), format="%Y%m%d")

## load inflation
cpi <- read.csv("data/CPILFENS.csv")
cpi$DATE <- as.Date(cpi$DATE, format="%Y-%m-%d")
cpi$yyyymm <- as.numeric(format(cpi$DATE, "%Y%m"))
cpi$pi <- c(NA, diff(log(cpi$CPILFENS)))
cpi$DATE <- NULL
cpi$CPILFENS <- NULL
df <- merge(df, cpi, all.x=TRUE)
df$pi <- df$pi*1200 ## per year, percent

## load PTR
ptr <- read.csv("data/ptrcpi.csv")
ptr$date <- as.Date(ptr$date, format="%m/%d/%Y")
ptr$yyyymm <- as.numeric(format(ptr$date, "%Y%m")) + 1 # middle month of the quarter
ptr$date <- NULL
names(ptr) <- c("ptr", "yyyymm")
df <- merge(df, ptr, all.x=TRUE)
## df$ptr <- df$ptr/1200  ## per month, decimal

## interpolate (later replace by appropriate handling of missing values)
require(zoo)
df$ptr <- na.locf(df$ptr)

scale <- 1 # 1/1200

theta2pars <- function(theta) {
    pars <- list(Sigma = diag(scale*c(exp(theta[1:5]))), # 5 shock variances
                 sig2 = scale*exp(theta[6:8]),  # 3 meas error variances -- inflation, yields, pi*
                 mu = c(0, 0, 0, 0, scale*theta[9]),
                 phi = diag(c(1, exp(theta[10])/(1+exp(theta[10])), 1, exp(theta[11])/(1+exp(theta[11])), exp(theta[12])/(1+exp(theta[12])))),
                 lam0 = matrix(scale*c(theta[13:16], 0), 5, 1),
                 lam1 = scale*cbind(matrix(0, 5, 4), c(theta[17:20], 0)))
                 ## only r* and pi* risk priced:
                 ## lam0 = matrix(scale*c(theta[13], 0, theta[14], 0, 0), 5, 1),
                 ## lam1 = scale*cbind(matrix(0, 5, 4), c(theta[15], 0, theta[16], 0, 0)))
    pars$Omega <- pars$Sigma %*% t(pars$Sigma)
    pars
}

pars2theta <- function(pars)
    c(log(diag(pars$Sigma)/scale), log(pars$sig2/scale),
      pars$mu[5]/scale,
      log(diag(pars$phi)[c(2,4,5)]/(1-diag(pars$phi)[c(2,4,5)])),
      pars$lam0[1:4]/scale, pars$lam1[1:4,5]/scale)
      ## pars$lam0[c(1,3)]/scale, pars$lam1[c(1,3),5]/scale) # only r* and pi* risk priced

affineLoadings <- function(pars) {
    ## globals: mats
    J <- length(mats)
    A <- matrix(NA, 1, J)
    B <- matrix(NA, 5, J)
    Atmp <- 0
    Btmp <- rep(0, 5)
    muQ <- pars$mu - pars$lam0
    phiQ <- pars$phi - pars$lam1
    phiQp <- t(phiQ)
    delta0 <- -0.5*pars$sig2[1]
    delta1 <- c(1,1,1,1,0)
    for (n in 1:max(mats)) {
        Atmp <- Atmp + crossprod(muQ, Btmp) + .5 * t(Btmp) %*% pars$Omega %*% Btmp - delta0
        Btmp <- phiQp %*% Btmp - delta1
        ind <- mats==n
        if (any(ind)) {
            A[which(ind)] <- - Atmp/n
            B[,which(ind)] <- - Btmp/n
        }
    }
    list(A=A, B=B)
}

kalmanDTSM <- function(pars, smooth=FALSE) {
    ## globals: mats, df, yield.cols
    loads <- affineLoadings(pars)
    ## measurement equation: J yields, inflation, PTR
    J <- length(mats)
    ct <- matrix(c(loads$A, 0, 0), J+2, 1)
    Zt <- array(rbind(t(loads$B),       # yields
                      c(1,1,0,0,0),  # inflation
                      c(1,0,0,0,0)), # PTR
                c(J+2, 5, 1))
    GGt <- array(diag(c(rep(pars$sig2[2], J), pars$sig2[1], pars$sig2[3])), c(J+2, J+2, 1))
    ## state equation
    dt <- matrix(pars$mu, 5, 1)
    Tt <- array(pars$phi, c(5, 5, 1))
    HHt <- array(pars$Omega, c(5, 5, 1))
    ## initial conditions
    a0 <- rep(0, 5)
    P0 <- 100*diag(5)
    ## data
    yt <- rbind(t(df[yield.cols]),
                c(tail(df$pi, -1), tail(df$pi, 1)),
                df$ptr)
    ## kalman filter
    if (smooth) {
        fkf.R(a0=a0, P0=P0, dt=dt, ct=ct, Tt=Tt, Zt=Zt, HHt=HHt, GGt=GGt, yt=yt, smooth=TRUE)
    } else {
        require(FKF)
        rval <- fkf(a0=a0, P0=P0, dt=dt, ct=ct, Tt=Tt, Zt=Zt, HHt=HHt, GGt=GGt, yt=yt)
        if (!(isTRUE(all.equal(rval$status, c(0,0))))) {
            stop("unsuccessful call to fkf()\n")
            ## fkf.R(a0=a0, P0=P0, dt=dt, ct=ct, Tt=Tt, Zt=Zt, HHt=HHt, GGt=GGt, yt=yt)
        } else {
            rval
        }
    }
}

obj <- function(theta) {
    pars <- theta2pars(theta)
    rval <- 1e6
    try(rval <- -kalmanDTSM(pars)$logLik, silent=TRUE)
    rval
}

startingValues <- function() {
    rho0 <- runif(3, 0.8, .99)
    dSigma <- rbeta(5, 1, 3)  # between 0 and 1, much mass close to zero
    sig <- c(runif(1, .5, 1), runif(2, .05, .15))
    theta0 <- c(log(dSigma/scale),
                log(sig^2/scale),
                rnorm(1)/20,
                log(rho0/(1-rho0)),
                rnorm(8)/20)
                ## rnorm(4)/20) # only r* and pi* risk priced
}
goodStartingValues <- function(n=10000) {
    ## evaluate LLK at n random starting values
    ## return best ones
    thetas <- replicate(n, startingValues())
    negllks <- apply(thetas, 2, obj)
    thetas[,which.min(negllks)]
}

## scaling/starting values
## number of parameters
N <- 5+8+4+3
## N <- 5+4+4+3 # only r* and pi* risk priced
theta <- goodStartingValues(1000)
pars <- theta2pars(theta)
stopifnot(isTRUE(all.equal(theta, pars2theta(pars))))

## optimization from random starting values
nstarts <- 3
cat("# Optimization from", nstarts, "different starting values\n")

doOptim <- function(...) {
    theta0 <- goodStartingValues()
    llk0 <- -obj(theta0)
    cat('LLK at starting point:', llk0, '\n')
    i <- 1; improvement <- Inf; llk <- llk0
    theta <- theta0
    while (improvement>.1) {
        res <- optim(theta, obj, control=list(maxit=5000))
        improvement <- -res$value - llk
        llk <- -res$value
        theta <- res$par
        cat('iteration ', i,', likelihood = ', llk,'\n')
        i <- i + 1
    }
    cat('improvement = ', improvement, ' -- proceed to final step\n')
    res <- optim(theta, obj, control=list(maxit=50000))
    cat('final Nelder-Mead step, likelihood = ', -res$value, "\n")
    theta <- res$par
    llk <- -res$value
    print(res$message)
    list(theta0=theta0, llk0=llk0, theta=theta, llk=llk, conv=res$convergence)
}

rvals <- lapply(1:nstarts, doOptim)

nms <- c("starting LLK", "optimal LLK", "convergence")
tbl <- matrix(NA, nstarts, length(nms))
colnames(tbl) <- nms
for (i in seq_along(rvals))
    tbl[i, ] <- unlist(rvals[[i]][c("llk0", "llk", "conv")])
print(round(tbl[order(tbl[,2], decreasing=TRUE),], 2))

ind <- which.max(tbl[,2])
theta <- rvals[[ind]]$theta
pars <- theta2pars(theta)
cat("best LLK: ", rvals[[ind]]$llk, "\n")
cat("check max:", -obj(theta), "\n")
cat("check max:", kalmanDTSM(pars)$logLik, "\n")

## final optimization
cat("# Final optimization. LLK at starting values:", -obj(theta), "\n")
cat("# Nelder-Mead optimization...\n")
rval <- optim(theta, obj, control=list(maxit=50000))
cat("# Improved to:", -rval$value, "\n")
print(rval)
theta <- rval$par

## cat("# 2. gradient-based method...\n")
## rval <- optim(theta, obj, method="BFGS", hessian=TRUE, control = list(trace=6, REPORT=1, maxit=5000))
## rval <- optim(theta, obj, method="L-BFGS-B", hessian=TRUE, control = list(trace=6, REPORT=1, maxit=5000))
## cat("# Improved to:", -rval$value, "\n")
## ## print(rval[-6])
## H <- rval$hessian
## cat("Hessian eigenvalues", round(eigen(H)$values, 4), "\n")
## theta <- rval$par
## checkKKT(theta, obj)

cat("likelihood at optimum:", -obj(theta), "\n")

## look at results
cat("# Parameters in unconstrained space and standard errors:\n")
require(numDeriv)
H <- hessian(obj, theta)
SEs <- rep(NA, N)
try(SEs <- sqrt(diag(solve(H))))
tbl2 <- cbind(theta, SEs, grad(obj, theta), diag(H), eigen(H)$values)
colnames(tbl2) <- c("theta", "SEs", "gradient", "diag(H)", "eigen(H)")
print(round(tbl2, d=4))

pars <- theta2pars(theta)
loads <- affineLoadings(pars)
print(pars)
print(round(loads$A, 2))
print(round(loads$B, 2))

## fit of measurement equations
Y <- df[yield.cols]
T <- nrow(Y)
kf <- kalmanDTSM(pars, smooth=TRUE)
X <- t(kf$att)
print(X)

Yhat <- rep(1, T) %*% loads$A + X %*% loads$B
cat("fit -- RMSE (bps)\n")
cat("inflation:", sqrt(mean((df$pi[2:T] - rowSums(X[1:(T-1), 1:2]))^2))*100, "\n")
cat("yields:", sqrt(mean((Y-Yhat)^2))*100, "\n")
cat("PTR:", sqrt(mean((df$ptr - X[, 1])^2))*100, "\n")
cat("SDs of meas. errors:", 100*sqrt(pars$sig2), "\n")

## plot r* - filtered and smoothed - vs. Laubach-Williams and others
df$rstarF <- kf$att[3,]
df$rstarS <- kf$atT[3,]
plot(df$Date, df$y10, type="l")

## plot inflation, pi*, PTR, and fitted inflation

## understand contributions of factors to yields

## decompose yields into term premium and expectations

## LPY(i), LPY(ii), CP regressions


